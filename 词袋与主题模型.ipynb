{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ee15c4",
   "metadata": {},
   "source": [
    "### 语料，向量空间和模型的概念"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619a7bc4",
   "metadata": {},
   "source": [
    "一个语料库是数字文档的集合。 这个集合是gensim的输入，它将从中推断文档的结构或主题。  \n",
    "从语料库中推断出的潜在结构（Latent Structure）可用于将主题分配给先前不存在于仅用于训练的语料库中的新文档。   \n",
    "出于这个原因，我们也将此集合称为训练语料库（Training Corpus）  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4a484a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\18438\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.203 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['商业 新知 : 知识图谱 为 内核 , 构建 商业 创新 服务 完整 生态 。',\n",
       " '如何 更好 利用 知识图谱 技术 做 反 欺诈 ?   360 金融 首席 数据 科学家 沈赟 开讲 。',\n",
       " '知识 管理   |   基于 知识图谱 的 国际 知识 管理 领域 可视化 分析 。',\n",
       " '一文 详解 达观 数据 知识图谱 技术 与 应用 。',\n",
       " '知识图谱 技术 落地 金融 行业 的 关键 四步 。',\n",
       " '一文 读懂 知识图谱 的 商业 应用 进程 及 技术 背景 。',\n",
       " '海云 数据 CPO 王斌 : 打造 大 数据 可视 分析 与 AI 应用 的 高科技 企业 。',\n",
       " '智能 产业 | 《 人工智能 标准化 白皮书 2018 》 带来 创新 创业 新 技术标准 。',\n",
       " '国家语委 重大 科研项目 “ 中华 经典 诗词 知识图谱 构建 技术 研究 ” 开题 。',\n",
       " '最全 知识图谱 介绍 : 关键技术 、 开放 数据 集 、 应用 案例 汇总 。',\n",
       " '中译 语通 Jove   Mind 知识图谱 平台   引领 企业 智能化 发展 。',\n",
       " '知识图谱 : 知识图谱 赋能 企业 数字化 转型 ， 为 企业 升级 转型 注入 新 能量 。']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "\n",
    "jieba.add_word('知识图谱') #防止“知识图谱”被切错词\n",
    "\n",
    "\n",
    "raw_corpus = ['商业新知:知识图谱为内核,构建商业创新服务完整生态。',\n",
    "'如何更好利用知识图谱技术做反欺诈? 360金融首席数据科学家沈赟开讲。',\n",
    "'知识管理 | 基于知识图谱的国际知识管理领域可视化分析。',\n",
    "'一文详解达观数据知识图谱技术与应用。',\n",
    "'知识图谱技术落地金融行业的关键四步。',\n",
    "'一文读懂知识图谱的商业应用进程及技术背景。',\n",
    "'海云数据CPO王斌:打造大数据可视分析与AI应用的高科技企业。',\n",
    "'智能产业|《人工智能标准化白皮书2018》带来创新创业新技术标准。',\n",
    "'国家语委重大科研项目“中华经典诗词知识图谱构建技术研究”开题。',\n",
    "'最全知识图谱介绍:关键技术、开放数据集、应用案例汇总。',\n",
    "'中译语通Jove Mind知识图谱平台 引领企业智能化发展。',\n",
    "'知识图谱:知识图谱赋能企业数字化转型，为企业升级转型注入新能量。']\n",
    "\n",
    "\n",
    "raw_corpus = [' '.join(jieba.lcut(i)) for i in raw_corpus]  #对语料库中的文档进行分词，便于后续处理\n",
    "raw_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ad25a",
   "metadata": {},
   "source": [
    "收集语料库之后，通常会进行一系列的文本预处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4a5b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['：', '。', '?', '|', '《', '》', ':', '“', '”', '，', '、']\n",
    "# 移除常用词以及分词\n",
    "stoplist = [i.strip() for i in stop_words]\n",
    "\n",
    "\n",
    "#将文档中可能存在的西文字符小写化，按空格进行拆分，且去停用词\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in raw_corpus]\n",
    "\n",
    "#计算词频\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "\n",
    "# 仅保留词频数高于1的词汇\n",
    "processed_corpus = [[token for token in text if frequency[token] > 1] for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a9747",
   "metadata": {},
   "source": [
    "将语料库中的每个词汇与唯一的整数ID相关联。  \n",
    "使用gensim.corpora.Dictionary这个类来完成。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51aae13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(18 unique tokens: ['为', '创新', '商业', '构建', '知识图谱']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "dictionary = corpora.Dictionary(processed_corpus)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6584477f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '为'),\n",
       " (1, '创新'),\n",
       " (2, '商业'),\n",
       " (3, '构建'),\n",
       " (4, '知识图谱'),\n",
       " (5, '技术'),\n",
       " (6, '数据'),\n",
       " (7, '金融'),\n",
       " (8, '分析'),\n",
       " (9, '的'),\n",
       " (10, '知识'),\n",
       " (11, '管理'),\n",
       " (12, '一文'),\n",
       " (13, '与'),\n",
       " (14, '应用'),\n",
       " (15, '企业'),\n",
       " (16, '新'),\n",
       " (17, '转型')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dictionary.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd6214e",
   "metadata": {},
   "source": [
    "#### 向量空间"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61bc1e1",
   "metadata": {},
   "source": [
    "为了推断语料库中的潜在结构（Latent Structure），我们需要一种可用于数学操作（比如，加减乘除等运算）的文档表示方法。  \n",
    "一种方法是将每个文档表示为向量。有各种用于创建文档的向量表示的方法，其中一个简单的方法是词袋模型(Bag-of-Words Model)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43999133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'为': 0, '创新': 1, '商业': 2, '构建': 3, '知识图谱': 4, '技术': 5, '数据': 6, '金融': 7, '分析': 8, '的': 9, '知识': 10, '管理': 11, '一文': 12, '与': 13, '应用': 14, '企业': 15, '新': 16, '转型': 17}\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b652cf",
   "metadata": {},
   "source": [
    "doc2bow方法为该语句创建词袋表示，该方法返回词汇计数的稀疏表示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "357b65b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (4, 1), (15, 1), (17, 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc = \"知识图谱 为 企业 转型 助力\"  #已分词，便于后续处理\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "new_vec  #第一个元素对应字典中的词汇ID 第二个元素对应该词汇的计数 #可以看到这里向量化后按照索引进行了排序 第一个不是“知识图谱”，而是“为”。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ea5d7b",
   "metadata": {},
   "source": [
    "#### 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2c3e2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.5320703276607741),\n",
       " (4, 0.054141134526709565),\n",
       " (15, 0.4116657998035457),\n",
       " (17, 0.737903227562547)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import models\n",
    "# 训练模型\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "\n",
    "tfidf[dictionary.doc2bow(\"知识图谱 为 企业 转型 助力\".split())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf6185c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1)],\n",
       " [(4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(4, 1), (8, 1), (9, 1), (10, 2), (11, 2)],\n",
       " [(4, 1), (5, 1), (6, 1), (12, 1), (13, 1), (14, 1)],\n",
       " [(4, 1), (5, 1), (7, 1), (9, 1)],\n",
       " [(2, 1), (4, 1), (5, 1), (9, 1), (12, 1), (14, 1)],\n",
       " [(6, 2), (8, 1), (9, 1), (13, 1), (14, 1), (15, 1)],\n",
       " [(1, 1), (16, 1)],\n",
       " [(3, 1), (4, 1), (5, 1)],\n",
       " [(4, 1), (6, 1), (14, 1)],\n",
       " [(4, 1), (15, 1)],\n",
       " [(0, 1), (4, 2), (15, 2), (16, 1), (17, 2)]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不同于TfidfVectorizer, TfidfMode的数据输入格式如下：需要先计算出每个词的索引和计数\n",
    "bow_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe72ebf8",
   "metadata": {},
   "source": [
    "#### 文本向量的转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea485b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e976d67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 15:02:21,809 : INFO : collecting document frequencies\n",
      "2022-03-25 15:02:21,811 : INFO : PROGRESS: processing document #0\n",
      "2022-03-25 15:02:21,812 : INFO : calculating IDF weights for 12 documents and 18 features (51 matrix non-zeros)\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "bow_corpus = [dictionary.doc2bow(text) for text in processed_corpus]\n",
    "tfidf = models.TfidfModel(bow_corpus) # 通过打印出的日志可以看到，该TF-IDF转换模型在这12个经词袋表示的文档中抽取出了18个特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "981f3db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1)],\n",
       " [(4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(4, 1), (8, 1), (9, 1), (10, 2), (11, 2)],\n",
       " [(4, 1), (5, 1), (6, 1), (12, 1), (13, 1), (14, 1)],\n",
       " [(4, 1), (5, 1), (7, 1), (9, 1)],\n",
       " [(2, 1), (4, 1), (5, 1), (9, 1), (12, 1), (14, 1)],\n",
       " [(6, 2), (8, 1), (9, 1), (13, 1), (14, 1), (15, 1)],\n",
       " [(1, 1), (16, 1)],\n",
       " [(3, 1), (4, 1), (5, 1)],\n",
       " [(4, 1), (6, 1), (14, 1)],\n",
       " [(4, 1), (15, 1)],\n",
       " [(0, 1), (4, 2), (15, 2), (16, 1), (17, 2)]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "047c7890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5144957554275265), (1, 0.8574929257125441)]\n"
     ]
    }
   ],
   "source": [
    "doc_bow = [(0, 3), (1, 5)]\n",
    "print(tfidf[doc_bow]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbbee18",
   "metadata": {},
   "source": [
    "#### 潜在语义索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "686a1739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['商业', '知识图谱', '为', '构建', '商业', '创新'],\n",
       " ['知识图谱', '技术', '金融', '数据'],\n",
       " ['知识', '管理', '知识图谱', '的', '知识', '管理', '分析'],\n",
       " ['一文', '数据', '知识图谱', '技术', '与', '应用'],\n",
       " ['知识图谱', '技术', '金融', '的'],\n",
       " ['一文', '知识图谱', '的', '商业', '应用', '技术'],\n",
       " ['数据', '数据', '分析', '与', '应用', '的', '企业'],\n",
       " ['创新', '新'],\n",
       " ['知识图谱', '构建', '技术'],\n",
       " ['知识图谱', '数据', '应用'],\n",
       " ['知识图谱', '企业'],\n",
       " ['知识图谱', '知识图谱', '企业', '转型', '为', '企业', '转型', '新']]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step1 get processed_corpus\n",
    "processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75169034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1)],\n",
       " [(4, 1), (5, 1), (6, 1), (7, 1)],\n",
       " [(4, 1), (8, 1), (9, 1), (10, 2), (11, 2)],\n",
       " [(4, 1), (5, 1), (6, 1), (12, 1), (13, 1), (14, 1)],\n",
       " [(4, 1), (5, 1), (7, 1), (9, 1)],\n",
       " [(2, 1), (4, 1), (5, 1), (9, 1), (12, 1), (14, 1)],\n",
       " [(6, 2), (8, 1), (9, 1), (13, 1), (14, 1), (15, 1)],\n",
       " [(1, 1), (16, 1)],\n",
       " [(3, 1), (4, 1), (5, 1)],\n",
       " [(4, 1), (6, 1), (14, 1)],\n",
       " [(4, 1), (15, 1)],\n",
       " [(0, 1), (4, 2), (15, 2), (16, 1), (17, 2)]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step2 processed_corpus > bow_corpus\n",
    "bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "80d464ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3 bow_corpus > corpus_tfidf\n",
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7b1c6",
   "metadata": {},
   "source": [
    "我们通过潜在语义索引（Latent Semantic Indexing）将前面转换得到的TF-IDF语料库转换到潜在的3-D空间（3-D因为笔者在这里设置了num_topics = 3）。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad89a686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 15:07:57,180 : INFO : using serial LSI version on this node\n",
      "2022-03-25 15:07:57,181 : INFO : updating model with new documents\n",
      "2022-03-25 15:07:57,184 : INFO : preparing a new chunk of documents\n",
      "2022-03-25 15:07:57,188 : INFO : using 100 extra samples and 2 power iterations\n",
      "2022-03-25 15:07:57,190 : INFO : 1st phase: constructing (18, 103) action matrix\n",
      "2022-03-25 15:07:57,196 : INFO : orthonormalizing (18, 103) action matrix\n",
      "2022-03-25 15:07:57,211 : INFO : 2nd phase: running dense svd on (18, 12) matrix\n",
      "2022-03-25 15:07:57,217 : INFO : computing the final decomposition\n",
      "2022-03-25 15:07:57,219 : INFO : keeping 3 factors (discarding 50.060% of energy spectrum)\n",
      "2022-03-25 15:07:57,221 : INFO : processed documents up to #12\n",
      "2022-03-25 15:07:57,226 : INFO : topic #0(1.667): 0.522*\"数据\" + 0.415*\"应用\" + 0.339*\"技术\" + 0.327*\"金融\" + 0.283*\"一文\" + 0.275*\"与\" + 0.244*\"的\" + 0.186*\"商业\" + 0.184*\"企业\" + 0.127*\"分析\"\n",
      "2022-03-25 15:07:57,227 : INFO : topic #1(1.276): 0.655*\"企业\" + -0.459*\"金融\" + -0.317*\"技术\" + 0.294*\"转型\" + -0.190*\"构建\" + 0.173*\"新\" + 0.151*\"与\" + 0.145*\"应用\" + 0.127*\"分析\" + 0.126*\"数据\"\n",
      "2022-03-25 15:07:57,229 : INFO : topic #2(1.259): 0.500*\"商业\" + 0.456*\"构建\" + 0.414*\"创新\" + -0.305*\"数据\" + 0.289*\"新\" + 0.260*\"为\" + 0.187*\"转型\" + -0.148*\"应用\" + 0.141*\"企业\" + -0.131*\"与\"\n"
     ]
    }
   ],
   "source": [
    "# step4 corpus_tfidf > Lsi\n",
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=3) # 初始化 LSI 转换\n",
    "corpus_lsi = lsi[corpus_tfidf] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07addec5",
   "metadata": {},
   "source": [
    "现在你可能想知道：这3个潜在的维度代表什么？ 让我们用models.LsiModel.show_topics()一探究竟："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78bc7d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.522*\"数据\" + 0.415*\"应用\" + 0.339*\"技术\" + 0.327*\"金融\" + 0.283*\"一文\" + 0.275*\"与\" + 0.244*\"的\" + 0.186*\"商业\" + 0.184*\"企业\" + 0.127*\"分析\"'),\n",
       " (1,\n",
       "  '0.655*\"企业\" + -0.459*\"金融\" + -0.317*\"技术\" + 0.294*\"转型\" + -0.190*\"构建\" + 0.173*\"新\" + 0.151*\"与\" + 0.145*\"应用\" + 0.127*\"分析\" + 0.126*\"数据\"'),\n",
       " (2,\n",
       "  '0.500*\"商业\" + 0.456*\"构建\" + 0.414*\"创新\" + -0.305*\"数据\" + 0.289*\"新\" + 0.260*\"为\" + 0.187*\"转型\" + -0.148*\"应用\" + 0.141*\"企业\" + -0.131*\"与\"')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f96020",
   "metadata": {},
   "source": [
    "由于LSI、LDA等主题模型在本质上属于软聚类（Soft Clustering），也就是说，每个主题上的概率就是文章对于这个主题的隶属度，同一个文档可能夹杂着多个主题，只是对应的各个主题的概率不同罢了。   \n",
    "上述文档对应的主题应该是混合的，每个主题的概率大小不尽相同，在实际应用中，我们一般找出其中概率最大的一个主题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c1f653de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.2205980967355469), (1, -0.0915199211338029), (2, 0.8064302977931628)]\n",
      "[(0, 0.6470631618916501), (1, -0.4193056582509369), (2, -0.1422387347128287)]\n",
      "[(0, 0.10495793818518592), (1, 0.033973174654206906), (2, -0.02988420923937445)]\n",
      "[(0, 0.7558863710004506), (1, 0.08278059466237589), (2, -0.165519159603095)]\n",
      "[(0, 0.5131637299454848), (1, -0.5333413310451962), (2, 0.01940115646669755)]\n",
      "[(0, 0.6060694248904178), (1, -0.1417807816122505), (2, 0.3176976421755372)]\n",
      "[(0, 0.7208233984239172), (1, 0.43579976296097106), (2, -0.24672666696702383)]\n",
      "[(0, 0.049205047521911065), (1, 0.1552595650274925), (2, 0.49733526951599605)]\n",
      "[(0, 0.26054052006849115), (1, -0.3064643335040266), (2, 0.4681367948232273)]\n",
      "[(0, 0.6716514876891511), (1, 0.19273932762594662), (2, -0.3127253597472357)]\n",
      "[(0, 0.19745672369019995), (1, 0.652210121288744), (2, 0.14590420350541577)]\n",
      "[(0, 0.14129975671133854), (1, 0.600309157305573), (2, 0.3717412874506636)]\n"
     ]
    }
   ],
   "source": [
    "for doc in corpus_lsi: # 显示每个文档归属于三个主题的概率\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91342cfb",
   "metadata": {},
   "source": [
    "#### 其他文本向量转换方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4950f56",
   "metadata": {},
   "source": [
    "随机映射（Random Projections）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20b0fb1",
   "metadata": {},
   "source": [
    "RP算法旨在减少向量空间的维度。 这是一种非常有效的（对内存和CPU友好）方法，通过加入一点随机性来近似表示文档之间的TF-IDF距离。 比较推荐的目标维度最好是几百/几千，具体数值取决于语料库的大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66dab72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 15:14:53,363 : INFO : no word id mapping provided; initializing from corpus, assuming identity\n",
      "2022-03-25 15:14:53,366 : INFO : constructing (3, 18) random matrix\n"
     ]
    }
   ],
   "source": [
    "model = models.RpModel(corpus_tfidf, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99faee43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文档的主题数\n",
    "model.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9634d69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 主题模型中参与训练的词汇数有多少？\n",
    "model.num_terms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5b1952a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0.6319815516471863), (1, -0.6319815516471863), (2, -0.6319815516471863)],\n",
       " [(0, 0.46322357654571533), (1, 0.09217122197151184), (2, 0.9979811906814575)],\n",
       " [(0, -0.06887989491224289),\n",
       "  (1, -0.7131474018096924),\n",
       "  (2, -0.21306325495243073)],\n",
       " [(0, 0.21194177865982056), (1, 0.6054527759552002), (2, 1.2720093727111816)],\n",
       " [(0, 0.4632236063480377), (1, -0.4632236063480377), (2, 0.44258639216423035)],\n",
       " [(0, 0.21194176375865936), (1, 0.196755513548851), (2, 0.196755513548851)],\n",
       " [(0, 0.845433235168457), (1, 0.11859847605228424), (2, 0.5240893363952637)],\n",
       " [(0, -0.8164966106414795), (1, 0.8164966106414795)],\n",
       " [(0, 0.21161195635795593),\n",
       "  (1, -0.21161195635795593),\n",
       "  (2, 0.8215587139129639)],\n",
       " [(0, 0.7436424493789673), (1, 0.8782217502593994), (2, 0.8782217502593994)],\n",
       " [(0, 0.49713781476020813),\n",
       "  (1, -0.49713781476020813),\n",
       "  (2, 0.6477042436599731)],\n",
       " [(0, 0.6825988292694092),\n",
       "  (1, -0.6825988292694092),\n",
       "  (2, -0.16955256462097168)]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in model[corpus_tfidf]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b86adfd",
   "metadata": {},
   "source": [
    "隐狄利克雷分配模型（Latent Dirichlet Allocation, LDA）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0f30cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 15:18:14,394 : INFO : using symmetric alpha at 0.3333333333333333\n",
      "2022-03-25 15:18:14,397 : INFO : using symmetric eta at 0.3333333333333333\n",
      "2022-03-25 15:18:14,398 : INFO : using serial LDA version on this node\n",
      "2022-03-25 15:18:14,403 : INFO : running online (single-pass) LDA training, 3 topics, 1 passes over the supplied corpus of 12 documents, updating model once every 12 documents, evaluating perplexity every 12 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-03-25 15:18:14,407 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-03-25 15:18:14,426 : INFO : -5.027 per-word bound, 32.6 perplexity estimate based on a held-out corpus of 12 documents with 21 words\n",
      "2022-03-25 15:18:14,427 : INFO : PROGRESS: pass 0, at document #12/12\n",
      "2022-03-25 15:18:14,444 : INFO : topic #0 (0.333): 0.136*\"金融\" + 0.115*\"技术\" + 0.096*\"构建\" + 0.081*\"创新\" + 0.075*\"新\" + 0.068*\"数据\" + 0.061*\"的\" + 0.048*\"知识图谱\" + 0.040*\"企业\" + 0.035*\"应用\"\n",
      "2022-03-25 15:18:14,445 : INFO : topic #1 (0.333): 0.101*\"转型\" + 0.096*\"商业\" + 0.084*\"为\" + 0.081*\"企业\" + 0.065*\"创新\" + 0.061*\"新\" + 0.061*\"构建\" + 0.047*\"与\" + 0.047*\"数据\" + 0.044*\"应用\"\n",
      "2022-03-25 15:18:14,447 : INFO : topic #2 (0.333): 0.109*\"应用\" + 0.107*\"数据\" + 0.088*\"企业\" + 0.082*\"一文\" + 0.070*\"与\" + 0.068*\"的\" + 0.060*\"分析\" + 0.059*\"管理\" + 0.059*\"知识\" + 0.054*\"商业\"\n",
      "2022-03-25 15:18:14,449 : INFO : topic diff=1.007176, rho=1.000000\n"
     ]
    }
   ],
   "source": [
    "model = models.LdaModel(corpus_tfidf, id2word=dictionary, num_topics=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c2c6bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.136*\"金融\" + 0.115*\"技术\" + 0.096*\"构建\" + 0.081*\"创新\" + 0.075*\"新\" + 0.068*\"数据\" + 0.061*\"的\" + 0.048*\"知识图谱\" + 0.040*\"企业\" + 0.035*\"应用\"'),\n",
       " (1,\n",
       "  '0.101*\"转型\" + 0.096*\"商业\" + 0.084*\"为\" + 0.081*\"企业\" + 0.065*\"创新\" + 0.061*\"新\" + 0.061*\"构建\" + 0.047*\"与\" + 0.047*\"数据\" + 0.044*\"应用\"'),\n",
       " (2,\n",
       "  '0.109*\"应用\" + 0.107*\"数据\" + 0.088*\"企业\" + 0.082*\"一文\" + 0.070*\"与\" + 0.068*\"的\" + 0.060*\"分析\" + 0.059*\"管理\" + 0.059*\"知识\" + 0.054*\"商业\"')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 展示主题模型中的各个主体及其主题词分布情况：\n",
    "model.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532cd0a2",
   "metadata": {},
   "source": [
    "层次狄利克雷过程（Hierarchical Dirichlet Process, HDP）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32090b76",
   "metadata": {},
   "source": [
    "HDP是一种非参数贝叶斯方法（跟其他的主题模型不同，它不需要事先确定主题的数量）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "be1d2a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 15:19:13,499 : WARNING : likelihood is decreasing!\n",
      "2022-03-25 15:19:13,501 : WARNING : likelihood is decreasing!\n",
      "2022-03-25 15:19:13,510 : INFO : (0, '0.164*知识 + 0.149*管理 + 0.096*应用 + 0.096*技术 + 0.092*构建 + 0.079*转型 + 0.064*数据 + 0.051*商业 + 0.045*知识图谱 + 0.040*创新')\n",
      "2022-03-25 15:19:13,512 : INFO : (1, '0.247*企业 + 0.161*商业 + 0.078*知识 + 0.070*技术 + 0.070*金融 + 0.061*分析 + 0.059*与 + 0.054*应用 + 0.036*数据 + 0.033*一文')\n",
      "2022-03-25 15:19:13,513 : INFO : (2, '0.181*创新 + 0.166*金融 + 0.121*分析 + 0.093*企业 + 0.081*一文 + 0.076*商业 + 0.048*的 + 0.046*数据 + 0.036*与 + 0.035*转型')\n",
      "2022-03-25 15:19:13,513 : INFO : (3, '0.175*的 + 0.132*管理 + 0.106*与 + 0.099*构建 + 0.079*创新 + 0.074*一文 + 0.050*分析 + 0.047*数据 + 0.046*为 + 0.040*知识')\n",
      "2022-03-25 15:19:13,514 : INFO : (4, '0.273*技术 + 0.138*与 + 0.110*创新 + 0.105*一文 + 0.069*为 + 0.065*知识 + 0.035*企业 + 0.034*商业 + 0.033*分析 + 0.033*应用')\n",
      "2022-03-25 15:19:13,517 : INFO : (5, '0.201*分析 + 0.149*商业 + 0.124*一文 + 0.108*管理 + 0.098*构建 + 0.044*应用 + 0.040*数据 + 0.036*技术 + 0.035*知识 + 0.029*知识图谱')\n",
      "2022-03-25 15:19:13,519 : INFO : (6, '0.146*技术 + 0.116*构建 + 0.111*企业 + 0.088*金融 + 0.084*创新 + 0.077*应用 + 0.073*商业 + 0.045*新 + 0.041*为 + 0.039*转型')\n",
      "2022-03-25 15:19:13,521 : INFO : (7, '0.210*技术 + 0.135*金融 + 0.125*构建 + 0.095*转型 + 0.093*创新 + 0.063*与 + 0.061*知识 + 0.039*数据 + 0.035*的 + 0.031*应用')\n",
      "2022-03-25 15:19:13,524 : INFO : (8, '0.179*应用 + 0.139*的 + 0.138*转型 + 0.102*与 + 0.096*一文 + 0.064*分析 + 0.062*创新 + 0.053*管理 + 0.041*数据 + 0.040*为')\n",
      "2022-03-25 15:19:13,524 : INFO : (9, '0.108*金融 + 0.091*为 + 0.089*技术 + 0.085*与 + 0.084*应用 + 0.070*商业 + 0.070*管理 + 0.068*的 + 0.059*转型 + 0.052*新')\n",
      "2022-03-25 15:19:13,526 : INFO : (10, '0.246*新 + 0.136*数据 + 0.120*构建 + 0.097*应用 + 0.067*知识 + 0.062*金融 + 0.058*企业 + 0.053*管理 + 0.037*分析 + 0.027*技术')\n",
      "2022-03-25 15:19:13,528 : INFO : (11, '0.152*与 + 0.149*知识 + 0.105*应用 + 0.084*知识图谱 + 0.074*构建 + 0.060*新 + 0.057*商业 + 0.051*金融 + 0.050*技术 + 0.049*的')\n",
      "2022-03-25 15:19:13,529 : INFO : (12, '0.200*企业 + 0.108*技术 + 0.100*知识 + 0.099*创新 + 0.086*分析 + 0.085*转型 + 0.075*新 + 0.067*数据 + 0.059*金融 + 0.031*一文')\n",
      "2022-03-25 15:19:13,533 : INFO : (13, '0.337*的 + 0.157*转型 + 0.107*数据 + 0.079*知识 + 0.059*商业 + 0.051*分析 + 0.049*与 + 0.041*为 + 0.029*构建 + 0.026*知识图谱')\n",
      "2022-03-25 15:19:13,534 : INFO : (14, '0.230*应用 + 0.127*商业 + 0.108*新 + 0.093*为 + 0.082*管理 + 0.081*转型 + 0.068*一文 + 0.044*知识图谱 + 0.038*构建 + 0.031*数据')\n",
      "2022-03-25 15:19:13,536 : INFO : (15, '0.135*新 + 0.127*知识 + 0.100*的 + 0.086*分析 + 0.080*商业 + 0.077*一文 + 0.069*金融 + 0.062*构建 + 0.047*知识图谱 + 0.046*技术')\n",
      "2022-03-25 15:19:13,538 : INFO : (16, '0.149*构建 + 0.138*转型 + 0.109*创新 + 0.088*新 + 0.070*分析 + 0.069*与 + 0.062*技术 + 0.058*数据 + 0.058*一文 + 0.039*为')\n",
      "2022-03-25 15:19:13,541 : INFO : (17, '0.130*的 + 0.123*管理 + 0.110*知识图谱 + 0.081*一文 + 0.077*技术 + 0.076*金融 + 0.068*转型 + 0.060*为 + 0.047*新 + 0.037*数据')\n",
      "2022-03-25 15:19:13,543 : INFO : (18, '0.146*转型 + 0.134*技术 + 0.110*一文 + 0.087*知识 + 0.076*分析 + 0.070*管理 + 0.070*应用 + 0.058*数据 + 0.052*企业 + 0.048*金融')\n",
      "2022-03-25 15:19:13,545 : INFO : (19, '0.218*商业 + 0.073*与 + 0.073*企业 + 0.071*分析 + 0.062*为 + 0.061*应用 + 0.060*一文 + 0.060*管理 + 0.050*新 + 0.045*知识')\n"
     ]
    }
   ],
   "source": [
    "model = models.HdpModel(corpus_tfidf, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f154657d",
   "metadata": {},
   "source": [
    "#### 主题模型的主题数确定与可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3691540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import ldamodel\n",
    "from gensim.models import CoherenceModel, LdaModel\n",
    "from gensim import models\n",
    "import numpy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5b1416d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 15:31:20,784 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2022-03-25 15:31:20,787 : INFO : built Dictionary(22 unique tokens: ['叶子', '树上', '椭圆形', '苹果', '植物']...) from 13 documents (total 50 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "            ['苹果','叶子','椭圆形','树上'],\n",
    "            ['植物','叶子','绿色','落叶乔木'],\n",
    "            ['水果','苹果','红彤彤','味道'],\n",
    "            ['苹果','落叶乔木','树上','水果'],\n",
    "            ['植物','营养','水果','维生素'],\n",
    "            ['营养','维生素','苹果','成分'],\n",
    "            ['互联网','电脑','智能手机','高科技'],\n",
    "            ['苹果','公司','互联网','品质'],\n",
    "            ['乔布斯','苹果','硅谷'],\n",
    "            ['电脑','智能手机','苹果','乔布斯'], \n",
    "            ['苹果','电脑','品质','生意'],\n",
    "            ['电脑','品质','乔布斯'],\n",
    "            ['苹果','公司','生意','硅谷']\n",
    "\n",
    "            ]\n",
    "\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132a5ca8",
   "metadata": {},
   "source": [
    "接下来，笔者将训练两个主题模型，差异在于主题数的不同，按照笔者构建的语料库构成来看，主题数应该是2，假如是其他的主题数，模型的效果应该不好。  \n",
    "下面，基于假设，“好”的主题模型的主题数为2，“坏”的主题模型的主题数为6。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1691e131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 15:31:52,768 : INFO : using symmetric alpha at 0.5\n",
      "2022-03-25 15:31:52,770 : INFO : using symmetric eta at 0.5\n",
      "2022-03-25 15:31:52,772 : INFO : using serial LDA version on this node\n",
      "2022-03-25 15:31:52,775 : INFO : running online (single-pass) LDA training, 2 topics, 1 passes over the supplied corpus of 13 documents, updating model once every 13 documents, evaluating perplexity every 13 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-03-25 15:31:52,777 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-03-25 15:31:52,805 : INFO : -3.928 per-word bound, 15.2 perplexity estimate based on a held-out corpus of 13 documents with 50 words\n",
      "2022-03-25 15:31:52,806 : INFO : PROGRESS: pass 0, at document #13/13\n",
      "2022-03-25 15:31:52,823 : INFO : topic #0 (0.500): 0.134*\"苹果\" + 0.067*\"水果\" + 0.064*\"公司\" + 0.064*\"落叶乔木\" + 0.063*\"叶子\" + 0.062*\"植物\" + 0.061*\"树上\" + 0.054*\"生意\" + 0.052*\"品质\" + 0.044*\"互联网\"\n",
      "2022-03-25 15:31:52,824 : INFO : topic #1 (0.500): 0.143*\"苹果\" + 0.106*\"电脑\" + 0.088*\"乔布斯\" + 0.061*\"智能手机\" + 0.059*\"品质\" + 0.047*\"营养\" + 0.045*\"维生素\" + 0.044*\"水果\" + 0.043*\"硅谷\" + 0.039*\"互联网\"\n",
      "2022-03-25 15:31:52,825 : INFO : topic diff=0.634011, rho=1.000000\n",
      "2022-03-25 15:31:52,827 : INFO : using symmetric alpha at 0.16666666666666666\n",
      "2022-03-25 15:31:52,828 : INFO : using symmetric eta at 0.16666666666666666\n",
      "2022-03-25 15:31:52,829 : INFO : using serial LDA version on this node\n",
      "2022-03-25 15:31:52,833 : INFO : running online (single-pass) LDA training, 6 topics, 1 passes over the supplied corpus of 13 documents, updating model once every 13 documents, evaluating perplexity every 13 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2022-03-25 15:31:52,835 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-03-25 15:31:52,855 : INFO : -6.238 per-word bound, 75.5 perplexity estimate based on a held-out corpus of 13 documents with 50 words\n",
      "2022-03-25 15:31:52,856 : INFO : PROGRESS: pass 0, at document #13/13\n",
      "2022-03-25 15:31:52,870 : INFO : topic #1 (0.167): 0.123*\"苹果\" + 0.122*\"乔布斯\" + 0.066*\"落叶乔木\" + 0.066*\"硅谷\" + 0.066*\"电脑\" + 0.066*\"水果\" + 0.066*\"植物\" + 0.066*\"绿色\" + 0.066*\"叶子\" + 0.066*\"红彤彤\"\n",
      "2022-03-25 15:31:52,872 : INFO : topic #5 (0.167): 0.152*\"苹果\" + 0.152*\"品质\" + 0.152*\"公司\" + 0.152*\"互联网\" + 0.022*\"电脑\" + 0.022*\"乔布斯\" + 0.022*\"水果\" + 0.022*\"树上\" + 0.022*\"植物\" + 0.022*\"硅谷\"\n",
      "2022-03-25 15:31:52,874 : INFO : topic #4 (0.167): 0.046*\"苹果\" + 0.046*\"电脑\" + 0.046*\"乔布斯\" + 0.046*\"水果\" + 0.046*\"品质\" + 0.046*\"硅谷\" + 0.045*\"树上\" + 0.045*\"营养\" + 0.045*\"互联网\" + 0.045*\"维生素\"\n",
      "2022-03-25 15:31:52,875 : INFO : topic #3 (0.167): 0.138*\"苹果\" + 0.138*\"维生素\" + 0.138*\"营养\" + 0.074*\"乔布斯\" + 0.074*\"电脑\" + 0.074*\"水果\" + 0.074*\"智能手机\" + 0.074*\"植物\" + 0.074*\"成分\" + 0.011*\"品质\"\n",
      "2022-03-25 15:31:52,876 : INFO : topic #2 (0.167): 0.186*\"苹果\" + 0.100*\"电脑\" + 0.100*\"树上\" + 0.100*\"品质\" + 0.100*\"水果\" + 0.100*\"落叶乔木\" + 0.100*\"生意\" + 0.014*\"乔布斯\" + 0.014*\"营养\" + 0.014*\"维生素\"\n",
      "2022-03-25 15:31:52,878 : INFO : topic diff=3.480400, rho=1.000000\n"
     ]
    }
   ],
   "source": [
    "numpy.random.seed(1) # 设置随即种子数，以便相同的设置能跑出相同的结果，可复现\n",
    "goodLdaModel = LdaModel(corpus=corpus, id2word=dictionary,\n",
    "     iterations=50, num_topics=2)\n",
    "badLdaModel = LdaModel(corpus=corpus, id2word=dictionary, \n",
    "     iterations=50, num_topics=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b415899",
   "metadata": {},
   "source": [
    "通过指标确定合理的主题数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16996345",
   "metadata": {},
   "source": [
    "1 使用U_Mass Coherence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c25a191a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-18.78459503442916\n",
      "-18.83035774373808\n"
     ]
    }
   ],
   "source": [
    "goodcm = CoherenceModel(model=goodLdaModel, corpus=corpus, \n",
    "       dictionary=dictionary, coherence='u_mass')\n",
    "badcm = CoherenceModel(model=badLdaModel, corpus=corpus,\n",
    "       dictionary=dictionary, coherence='u_mass')\n",
    "\n",
    "print(goodcm.get_coherence())\n",
    "print(badcm.get_coherence()) #虽然数值差异不大，但仍能看出“好”的主题模型的U_Mass Coherence要大于坏的模型的数值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54eaa80",
   "metadata": {},
   "source": [
    "2 使用 C_V coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "88416f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 15:33:04,507 : INFO : using ParallelWordOccurrenceAccumulator(processes=11, batch_size=64) to estimate probabilities from sliding windows\n",
      "2022-03-25 15:33:08,222 : INFO : 11 accumulators retrieved from output queue\n",
      "2022-03-25 15:33:08,247 : INFO : accumulated word occurrence stats for 13 virtual documents\n",
      "2022-03-25 15:33:08,344 : INFO : using ParallelWordOccurrenceAccumulator(processes=11, batch_size=64) to estimate probabilities from sliding windows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5880602397643417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 15:33:11,767 : INFO : 11 accumulators retrieved from output queue\n",
      "2022-03-25 15:33:11,785 : INFO : accumulated word occurrence stats for 13 virtual documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5868870960312388\n"
     ]
    }
   ],
   "source": [
    "goodcm = CoherenceModel(model=goodLdaModel, texts=texts, \n",
    "    dictionary=dictionary,  coherence='c_v')\n",
    "badcm = CoherenceModel(model=badLdaModel, texts=texts,\n",
    "    dictionary=dictionary,  coherence='c_v')\n",
    "\n",
    "print(goodcm.get_coherence())\n",
    "print(badcm.get_coherence()) # 跟上述结果一样，虽然数值差异不大，但“好”的主题模型的C_V coherence值仍要大于“坏”的主题模型的C_V coherence值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a74d0f",
   "metadata": {},
   "source": [
    "预测词汇的主题归属"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d38a5c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-25 15:35:54,000 : INFO : using autotuned alpha, starting with [0.5, 0.5]\n",
      "2022-03-25 15:35:54,002 : INFO : using symmetric eta at 0.5\n",
      "2022-03-25 15:35:54,004 : INFO : using serial LDA version on this node\n",
      "2022-03-25 15:35:54,005 : INFO : running online (single-pass) LDA training, 2 topics, 1 passes over the supplied corpus of 13 documents, updating model once every 13 documents, evaluating perplexity every 13 documents, iterating 500x with a convergence threshold of 0.001000\n",
      "2022-03-25 15:35:54,006 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2022-03-25 15:35:54,031 : INFO : -3.922 per-word bound, 15.2 perplexity estimate based on a held-out corpus of 13 documents with 50 words\n",
      "2022-03-25 15:35:54,032 : INFO : PROGRESS: pass 0, at document #13/13\n",
      "2022-03-25 15:35:54,057 : INFO : optimized alpha [0.6690984, 0.7567388]\n",
      "2022-03-25 15:35:54,060 : INFO : topic #0 (0.669): 0.143*\"苹果\" + 0.077*\"水果\" + 0.070*\"树上\" + 0.058*\"电脑\" + 0.048*\"叶子\" + 0.046*\"智能手机\" + 0.044*\"互联网\" + 0.044*\"红彤彤\" + 0.044*\"落叶乔木\" + 0.044*\"味道\"\n",
      "2022-03-25 15:35:54,062 : INFO : topic #1 (0.757): 0.135*\"苹果\" + 0.078*\"电脑\" + 0.075*\"乔布斯\" + 0.074*\"品质\" + 0.055*\"植物\" + 0.054*\"硅谷\" + 0.052*\"维生素\" + 0.050*\"生意\" + 0.048*\"公司\" + 0.042*\"营养\"\n",
      "2022-03-25 15:35:54,065 : INFO : topic diff=0.550176, rho=1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.143*\"苹果\" + 0.077*\"水果\" + 0.070*\"树上\" + 0.058*\"电脑\" + 0.048*\"叶子\"'), (1, '0.135*\"苹果\" + 0.078*\"电脑\" + 0.075*\"乔布斯\" + 0.074*\"品质\" + 0.055*\"植物\"')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('水果', 0.05612464)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ldamodel.LdaModel(corpus, id2word=dictionary,\n",
    "           iterations=500,num_topics=2,alpha='auto')\n",
    "\n",
    "print(model.show_topics(num_words=5))\n",
    "\n",
    "#根据主题模型运行出来的结果，序号为0的暂定为“水果”，序号为1的暂定为“公司”，用来测试几个词汇的主题归属情况\n",
    "topic_list = ['水果','公司']\n",
    "\n",
    "[(topic_list[i[0]],i[1]) for i in model.get_term_topics('树上')] # “树上”这个词汇更加靠近“水果”这个主题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed775450",
   "metadata": {},
   "source": [
    "预测文档的主题归属"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0f611be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, [0, 1]), (3, [0, 1]), (6, [0, 1])]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_fruit = ['苹果','树上','落叶乔木','苹果']\n",
    "bow_company = ['苹果','电脑','乔布斯']\n",
    "\n",
    "bow = model.id2word.doc2bow(bow_fruit)     # 现将文档转换为词袋表示\n",
    "doc_topics, word_topics, phi_values = model.get_document_topics(bow, per_word_topics=True)\n",
    "\n",
    "word_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11b4237",
   "metadata": {},
   "source": [
    "上面的结果应该这样理解：1、3、6对应文档bow_fruit中的3个词汇：'苹果'、'树上'、'落叶乔木'，它们的主题更加倾向于是“水果”，因为每个词汇的主题序号中，0都排在靠前的位置，也就是“水果”这个主题更为明显。  \n",
    "get_document_topics这个方法产生了3个值doc_topics、 word_topics和 phi_values。  \n",
    "对于phi_values而言，它包含特定词汇在各主题上的phi值，且按特征长度缩放。 Phi本质上是文档中某个词汇从属于某个主题的概率值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bb197b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, [(0, 0.9572513), (1, 0.042745788)]),\n",
       " (3, [(0, 1.5801868), (1, 0.4198111)]),\n",
       " (6, [(0, 0.789432), (1, 0.21056363)])]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587d9a46",
   "metadata": {},
   "source": [
    "通过get_document_topics来获取语料库中所有文档的“doc_topics”，“word_topics”和“phi_values”：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "70f69590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1), (3, 1)],\n",
       " [(0, 1), (4, 1), (5, 1), (6, 1)],\n",
       " [(3, 1), (7, 1), (8, 1), (9, 1)],\n",
       " [(1, 1), (3, 1), (6, 1), (8, 1)],\n",
       " [(4, 1), (8, 1), (10, 1), (11, 1)],\n",
       " [(3, 1), (10, 1), (11, 1), (12, 1)],\n",
       " [(13, 1), (14, 1), (15, 1), (16, 1)],\n",
       " [(3, 1), (13, 1), (17, 1), (18, 1)],\n",
       " [(3, 1), (19, 1), (20, 1)],\n",
       " [(3, 1), (14, 1), (15, 1), (19, 1)],\n",
       " [(3, 1), (15, 1), (18, 1), (21, 1)],\n",
       " [(15, 1), (18, 1), (19, 1)],\n",
       " [(3, 1), (17, 1), (20, 1), (21, 1)]]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b463c410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新文档:0 \n",
      " ['苹果', '叶子', '椭圆形', '树上']\n",
      "文档主题: [('水果', 0.802878), ('公司', 0.19712195)]\n",
      "词汇主题: [('叶子', [0, 1]), ('树上', [0, 1]), ('椭圆形', [0, 1]), ('苹果', [0, 1])]\n",
      "Phi值: [('叶子', [(0, 0.88831884), (1, 0.11167704)]), ('树上', [(0, 0.97451615), (1, 0.025481217)]), ('椭圆形', [(0, 0.9592283), (1, 0.040766396)]), ('苹果', [(0, 0.8653774), (1, 0.1346216)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "新文档:1 \n",
      " ['植物', '叶子', '绿色', '落叶乔木']\n",
      "文档主题: [('水果', 0.1982791), ('公司', 0.80172086)]\n",
      "词汇主题: [('叶子', [1, 0]), ('植物', [1, 0]), ('绿色', [1, 0]), ('落叶乔木', [1, 0])]\n",
      "Phi值: [('叶子', [(0, 0.17409904), (1, 0.825896)]), ('植物', [(0, 0.0402802), (1, 0.9597165)]), ('绿色', [(0, 0.046808325), (1, 0.9531854)]), ('落叶乔木', [(0, 0.14506549), (1, 0.85493)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "新文档:2 \n",
      " ['水果', '苹果', '红彤彤', '味道']\n",
      "文档主题: [('水果', 0.81959784), ('公司', 0.18040214)]\n",
      "词汇主题: [('苹果', [0, 1]), ('味道', [0, 1]), ('水果', [0, 1]), ('红彤彤', [0, 1])]\n",
      "Phi值: [('苹果', [(0, 0.8837181), (1, 0.116280995)]), ('味道', [(0, 0.9744483), (1, 0.025546927)]), ('水果', [(0, 0.9437744), (1, 0.056223415)]), ('红彤彤', [(0, 0.9761231), (1, 0.023872042)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "新文档:3 \n",
      " ['苹果', '落叶乔木', '树上', '水果']\n",
      "文档主题: [('水果', 0.782159), ('公司', 0.21784103)]\n",
      "词汇主题: [('树上', [0, 1]), ('苹果', [0, 1]), ('落叶乔木', [0, 1]), ('水果', [0, 1])]\n",
      "Phi值: [('树上', [(0, 0.969479), (1, 0.030518256)]), ('苹果', [(0, 0.84225804), (1, 0.15774098)]), ('落叶乔木', [(0, 0.84172726), (1, 0.15826833)]), ('水果', [(0, 0.9218339), (1, 0.078163885)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "新文档:4 \n",
      " ['植物', '营养', '水果', '维生素']\n",
      "文档主题: [('水果', 0.2515998), ('公司', 0.7484002)]\n",
      "词汇主题: [('植物', [1, 0]), ('水果', [1, 0]), ('维生素', [1, 0]), ('营养', [1, 0])]\n",
      "Phi值: [('植物', [(0, 0.061116047), (1, 0.9388804)]), ('水果', [(0, 0.36851728), (1, 0.6314789)]), ('维生素', [(0, 0.088081844), (1, 0.9119145)]), ('营养', [(0, 0.17772931), (1, 0.82226634)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "新文档:5 \n",
      " ['营养', '维生素', '苹果', '成分']\n",
      "文档主题: [('水果', 0.24823895), ('公司', 0.7517611)]\n",
      "词汇主题: [('苹果', [1, 0]), ('维生素', [1, 0]), ('营养', [1, 0]), ('成分', [1, 0])]\n",
      "Phi值: [('苹果', [(0, 0.20495564), (1, 0.7950433)]), ('维生素', [(0, 0.08612574), (1, 0.9138706)]), ('营养', [(0, 0.17416258), (1, 0.82583314)]), ('成分', [(0, 0.2118541), (1, 0.7881374)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "新文档:6 \n",
      " ['互联网', '电脑', '智能手机', '高科技']\n",
      "文档主题: [('水果', 0.6843654), ('公司', 0.3156346)]\n",
      "词汇主题: [('互联网', [0, 1]), ('智能手机', [0, 1]), ('电脑', [0, 1]), ('高科技', [0, 1])]\n",
      "Phi值: [('互联网', [(0, 0.7353799), (1, 0.2646157)]), ('智能手机', [(0, 0.75628036), (1, 0.24371532)]), ('电脑', [(0, 0.63118804), (1, 0.36880928)]), ('高科技', [(0, 0.9219591), (1, 0.07803505)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "新文档:7 \n",
      " ['苹果', '公司', '互联网', '品质']\n",
      "文档主题: [('水果', 0.20752859), ('公司', 0.7924714)]\n",
      "词汇主题: [('苹果', [1, 0]), ('互联网', [1, 0]), ('公司', [1, 0]), ('品质', [1, 0])]\n",
      "Phi值: [('苹果', [(0, 0.1564411), (1, 0.84355783)]), ('互联网', [(0, 0.16035876), (1, 0.83963674)]), ('公司', [(0, 0.09012792), (1, 0.90986824)]), ('品质', [(0, 0.049431216), (1, 0.9505664)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "新文档:8 \n",
      " ['乔布斯', '苹果', '硅谷']\n",
      "文档主题: [('水果', 0.20047978), ('公司', 0.7995202)]\n",
      "词汇主题: [('苹果', [1, 0]), ('乔布斯', [1, 0]), ('硅谷', [1, 0])]\n",
      "Phi值: [('苹果', [(0, 0.135229), (1, 0.86477)]), ('乔布斯', [(0, 0.038467567), (1, 0.96153015)]), ('硅谷', [(0, 0.04423638), (1, 0.95576006)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "新文档:9 \n",
      " ['电脑', '智能手机', '苹果', '乔布斯']\n",
      "文档主题: [('水果', 0.22309032), ('公司', 0.77690965)]\n",
      "词汇主题: [('苹果', [1, 0]), ('智能手机', [1, 0]), ('电脑', [1, 0]), ('乔布斯', [1, 0])]\n",
      "Phi值: [('苹果', [(0, 0.17488436), (1, 0.82511467)]), ('智能手机', [(0, 0.19596489), (1, 0.80403036)]), ('电脑', [(0, 0.11849175), (1, 0.88150626)]), ('乔布斯', [(0, 0.051435735), (1, 0.94856197)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "新文档:10 \n",
      " ['苹果', '电脑', '品质', '生意']\n",
      "文档主题: [('水果', 0.17784338), ('公司', 0.8221566)]\n",
      "词汇主题: [('苹果', [1, 0]), ('电脑', [1, 0]), ('品质', [1, 0]), ('生意', [1, 0])]\n",
      "Phi值: [('苹果', [(0, 0.12179363), (1, 0.8782054)]), ('电脑', [(0, 0.08084314), (1, 0.91915476)]), ('品质', [(0, 0.037431885), (1, 0.96256584)]), ('生意', [(0, 0.05535647), (1, 0.9446399)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "新文档:11 \n",
      " ['电脑', '品质', '乔布斯']\n",
      "文档主题: [('水果', 0.18384929), ('公司', 0.81615067)]\n",
      "词汇主题: [('电脑', [1, 0]), ('品质', [1, 0]), ('乔布斯', [1, 0])]\n",
      "Phi值: [('电脑', [(0, 0.07663722), (1, 0.92336065)]), ('品质', [(0, 0.03539749), (1, 0.9646002)]), ('乔布斯', [(0, 0.032396734), (1, 0.967601)])]\n",
      " \n",
      "-------------- \n",
      "\n",
      "新文档:12 \n",
      " ['苹果', '公司', '生意', '硅谷']\n",
      "文档主题: [('水果', 0.1740331), ('公司', 0.82596695)]\n",
      "词汇主题: [('苹果', [1, 0]), ('公司', [1, 0]), ('硅谷', [1, 0]), ('生意', [1, 0])]\n",
      "Phi值: [('苹果', [(0, 0.11741444), (1, 0.88258445)]), ('公司', [(0, 0.06634309), (1, 0.9336531)]), ('硅谷', [(0, 0.037883725), (1, 0.96211284)]), ('生意', [(0, 0.053221323), (1, 0.9467751)])]\n",
      " \n",
      "-------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_topics = model.get_document_topics(corpus, per_word_topics=True)\n",
    "\n",
    "cnt = 0\n",
    "for doc_topics, word_topics, phi_values in all_topics:\n",
    "    print('新文档:{} \\n'.format(cnt),texts[cnt])\n",
    "    doc_topics = [(topic_list[i[0]],i[1]) for i in doc_topics]\n",
    "    word_topics = [(dictionary.id2token [i[0]],i[1]) for i in word_topics]\n",
    "    phi_values = [(dictionary.id2token [i[0]],i[1]) for i in phi_values ]\n",
    "    print('文档主题:', doc_topics)\n",
    "    print('词汇主题:', word_topics)\n",
    "    print('Phi值:', phi_values)\n",
    "    print(\" \")\n",
    "    print('-------------- \\n')\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8139aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
