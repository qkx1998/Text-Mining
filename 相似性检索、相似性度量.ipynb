{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73df6254",
   "metadata": {},
   "source": [
    "#### 文本相似度检索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df623725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\18438\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.413 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "from collections import defaultdict\n",
    "from pprint import pprint  #使打印的格式更齐整\n",
    "import jieba\n",
    "\n",
    "#对特定长词进行控制，防止被分错词，影响后续的分析效果\n",
    "jieba.add_word('微信')      \n",
    "jieba.add_word('文本挖掘')   \n",
    "jieba.add_word('增长黑客')   \n",
    "jieba.add_word('小白')   \n",
    "jieba.add_word('大数据') \n",
    "\n",
    "\n",
    "docs = [\n",
    "        '数据挖掘实操｜用文本挖掘剖析近5万首《全唐诗》',\n",
    "        '以虎嗅网4W+文章的文本挖掘为例，展现数据分析的一整套流程',\n",
    "        '干货｜作为一个合格的“增长黑客”，你还得重视外部数据的分析！',\n",
    "        '文本挖掘从小白到精通（二）---语料库和词向量空间',\n",
    "        '文本挖掘从小白到精通（三）---主题模型和文本数据转换',\n",
    "        '文本挖掘从小白到精通（一）---语料、向量空间和模型的概念',\n",
    "        '以《大秦帝国之崛起》为例，来谈大数据舆情分析和文本挖掘',\n",
    "        '文本分类算法集锦，从小白到大牛，附代码注释和训练语料',\n",
    "        'Social Listening和传统市场调研的关系是怎样的？',\n",
    "        '【新媒体运营实操】如何做出一个精美的个性化词云'\n",
    "        '以哈尔滨冰雪大世界旅游的传播效应为例，谈数据新闻可视化的“魅惑”',\n",
    "        '万字干货｜10款数据分析“工具”，助你成为新媒体运营领域的“增长黑客”',\n",
    "        '如何用数据分析，搞定新媒体运营的定位和内容初始化？',\n",
    "        '当数据分析遭遇心理动力学：用户深层次的情感需求浮出水面',\n",
    "        '揭开微博转发传播的规律：以“人民日报”发布的G20文艺晚会微博为例',\n",
    "        '数据运营实操 | 如何运用数据分析对某个试运营项目进行“无死角”的复盘？',\n",
    "        '如何利用微信后台数据优化微信运营',\n",
    "        '如何利用Social Listening从社会化媒体中“提炼”有价值的信息？',\n",
    "        '用大数据文本挖掘，来洞察“共享单车”的行业现状及走势',\n",
    "        '从社交媒体传播和文本挖掘角度解读《欢乐颂2》',\n",
    "        '不懂数理和编程，如何运用免费的大数据工具获得行业洞察？',\n",
    "        '写给迷茫的你：如何运用运营思维规划自己的职业发展路径？',\n",
    "        '如何用聚类分析进行企业公众号的内容优化',\n",
    "        '傅园慧和她的“洪荒之力”的大数据舆情分析',\n",
    "        '数据运营|数据分析中，文本分析远比数值型分析重要！（上）'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de261568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['数据挖掘 实操 ｜ 用 文本挖掘 剖析 近 5 万首 《 全唐诗 》',\n",
       " '以虎 嗅网 4W + 文章 的 文本挖掘 为例 ， 展现 数据分析 的 一整套 流程',\n",
       " '干货 ｜ 作为 一个 合格 的 “ 增长黑客 ” ， 你 还 得 重视 外部 数据 的 分析 ！',\n",
       " '文本挖掘 从小 白到 精通 （ 二 ） - - - 语料库 和 词 向量 空间',\n",
       " '文本挖掘 从小 白到 精通 （ 三 ） - - - 主题 模型 和 文本 数据 转换',\n",
       " '文本挖掘 从小 白到 精通 （ 一 ） - - - 语料 、 向量 空间 和 模型 的 概念',\n",
       " '以 《 大秦 帝国 之 崛起 》 为例 ， 来谈 大数据 舆情 分析 和 文本挖掘',\n",
       " '文本 分类 算法 集锦 ， 从小 白到 大牛 ， 附 代码 注释 和 训练 语料',\n",
       " 'Social   Listening 和 传统 市场调研 的 关系 是 怎样 的 ？',\n",
       " '【 新 媒体 运营 实操 】 如何 做出 一个 精美 的 个性化 词云以 哈尔滨 冰雪 大 世界 旅游 的 传播效应 为例 ， 谈 数据 新闻 可视化 的 “ 魅惑 ”',\n",
       " '万字 干货 ｜ 10 款 数据分析 “ 工具 ” ， 助 你 成为 新 媒体 运营 领域 的 “ 增长黑客 ”',\n",
       " '如何 用 数据分析 ， 搞定 新 媒体 运营 的 定位 和 内容 初始化 ？',\n",
       " '当 数据分析 遭遇 心理 动力学 ： 用户 深层次 的 情感 需求 浮出 水面',\n",
       " '揭开 微博 转发 传播 的 规律 ： 以 “ 人民日报 ” 发布 的 G20 文艺晚会 微博为 例',\n",
       " '数据 运营 实操   |   如何 运用 数据分析 对 某个 试运营 项目 进行 “ 无 死角 ” 的 复盘 ？',\n",
       " '如何 利用微 信 后台 数据 优化 微信 运营',\n",
       " '如何 利用 Social   Listening 从 社会化 媒体 中 “ 提炼 ” 有 价值 的 信息 ？',\n",
       " '用 大数据 文本挖掘 ， 来 洞察 “ 共享 单车 ” 的 行业 现状及 走势',\n",
       " '从 社交 媒体 传播 和 文本挖掘 角度 解读 《 欢乐颂 2 》',\n",
       " '不 懂 数理 和 编程 ， 如何 运用 免费 的 大数据 工具 获得 行业 洞察 ？',\n",
       " '写给 迷茫 的 你 ： 如何 运用 运营 思维 规划 自己 的 职业 发展 路径 ？',\n",
       " '如何 用 聚类分析 进行 企业 公众 号 的 内容 优化',\n",
       " '傅园慧 和 她 的 “ 洪荒 之力 ” 的 大数据 舆情 分析',\n",
       " '数据 运营 | 数据分析 中 ， 文本 分析 远比 数值 型 分析 重要 ！ （ 上 ）']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [' '.join(jieba.lcut(i)) for i in docs]\n",
    "documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31733cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['数据挖掘', '实操', '用', '文本挖掘', '剖析', '近', '5', '万首', '全唐诗'], ['以虎', '嗅网', '4w', '文章', '的', '文本挖掘', '为例', '展现', '数据分析', '的', '一整套', '流程'], ['干货', '作为', '一个', '合格', '的', '增长黑客', '你', '还', '得', '重视', '外部', '数据', '的', '分析'], ['文本挖掘', '从小', '白到', '精通', '二', '语料库', '和', '词', '向量', '空间'], ['文本挖掘', '从小', '白到', '精通', '三', '主题', '模型', '和', '文本', '数据', '转换'], ['文本挖掘', '从小', '白到', '精通', '一', '语料', '向量', '空间', '和', '模型', '的', '概念'], ['以', '大秦', '帝国', '之', '崛起', '为例', '来谈', '大数据', '舆情', '分析', '和', '文本挖掘'], ['文本', '分类', '算法', '集锦', '从小', '白到', '大牛', '附', '代码', '注释', '和', '训练', '语料'], ['social', 'listening', '和', '传统', '市场调研', '的', '关系', '是', '怎样', '的'], ['新', '媒体', '运营', '实操', '如何', '做出', '一个', '精美', '的', '个性化', '词云以', '哈尔滨', '冰雪', '大', '世界', '旅游', '的', '传播效应', '为例', '谈', '数据', '新闻', '可视化', '的', '魅惑'], ['万字', '干货', '10', '款', '数据分析', '工具', '助', '你', '成为', '新', '媒体', '运营', '领域', '的', '增长黑客'], ['如何', '用', '数据分析', '搞定', '新', '媒体', '运营', '的', '定位', '和', '内容', '初始化'], ['当', '数据分析', '遭遇', '心理', '动力学', '用户', '深层次', '的', '情感', '需求', '浮出', '水面'], ['揭开', '微博', '转发', '传播', '的', '规律', '以', '人民日报', '发布', '的', 'g20', '文艺晚会', '微博为', '例'], ['数据', '运营', '实操', '如何', '运用', '数据分析', '对', '某个', '试运营', '项目', '进行', '无', '死角', '的', '复盘'], ['如何', '利用微', '信', '后台', '数据', '优化', '微信', '运营'], ['如何', '利用', 'social', 'listening', '从', '社会化', '媒体', '中', '提炼', '有', '价值', '的', '信息'], ['用', '大数据', '文本挖掘', '来', '洞察', '共享', '单车', '的', '行业', '现状及', '走势'], ['从', '社交', '媒体', '传播', '和', '文本挖掘', '角度', '解读', '欢乐颂', '2'], ['不', '懂', '数理', '和', '编程', '如何', '运用', '免费', '的', '大数据', '工具', '获得', '行业', '洞察'], ['写给', '迷茫', '的', '你', '如何', '运用', '运营', '思维', '规划', '自己', '的', '职业', '发展', '路径'], ['如何', '用', '聚类分析', '进行', '企业', '公众', '号', '的', '内容', '优化'], ['傅园慧', '和', '她', '的', '洪荒', '之力', '的', '大数据', '舆情', '分析'], ['数据', '运营', '数据分析', '中', '文本', '分析', '远比', '数值', '型', '分析', '重要', '上']]\n"
     ]
    }
   ],
   "source": [
    "# 去停用词\n",
    "stop_words = ['：', '。', '?', '|', '《', '》', ':', '“', '”', '，', '、', '+', '｜', '！', '（', '）', '-','【','】','？']\n",
    "# 移除常用词以及分词 \n",
    "stoplist = [i.strip() for i in stop_words]\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "for document in documents]\n",
    "\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e07b08e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用词袋模型提取问文本特征\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c55bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于构建好的词袋表示语料库，用LSI构建一个10维的向量空间\n",
    "# 值得注意的一个参数是power_iters，模型中的默认设为2，设置的数值越大，模型的精确度就越高，尤其是在训练语料较少的情况下，但训练语料过多的话，加大该数值会影响模型的运行效率。\n",
    "lsi = models.LsiModel(\n",
    "         corpus, \n",
    "         id2word=dictionary,\n",
    "         power_iters=100,\n",
    "         num_topics=10\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71896a65",
   "metadata": {},
   "source": [
    "现在，笔者设定的检索语句为“文本挖掘在舆情口碑挖掘中的作用很大”（需做分词处理）， 笔者想让结果按相似度的降序进行排列展示，也就是和查询语句相似度越高（相似度数值较大）的展示在上面。\n",
    "\n",
    "在这里我们只是单纯的考虑文本（词汇）的显式语义相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "002fb703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#查询语句为“文本挖掘在舆情口碑挖掘中的作用很大” \n",
    "doc = \"文本挖掘 在 舆情 口碑 挖掘 中 的 作用 很大 \"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow]      #将查询语句转换到LSI向量空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97056ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('以虎嗅网4W+文章的文本挖掘为例，展现数据分析的一整套流程', 0.3619939473795544),\n",
      " ('干货｜作为一个合格的“增长黑客”，你还得重视外部数据的分析！', 0.35781006161854967),\n",
      " ('文本挖掘从小白到精通（三）---主题模型和文本数据转换', 0.15847743278949084),\n",
      " ('文本挖掘从小白到精通（二）---语料库和词向量空间', 0.13785471597129512),\n",
      " ('【新媒体运营实操】如何做出一个精美的个性化词云以哈尔滨冰雪大世界旅游的传播效应为例，谈数据新闻可视化的“魅惑”',\n",
      "  0.05712771001193546),\n",
      " ('文本分类算法集锦，从小白到大牛，附代码注释和训练语料', -0.07801000538899819),\n",
      " ('以《大秦帝国之崛起》为例，来谈大数据舆情分析和文本挖掘', -0.13559364956572714),\n",
      " ('Social Listening和传统市场调研的关系是怎样的？', -0.24000311522407283),\n",
      " ('文本挖掘从小白到精通（一）---语料、向量空间和模型的概念', -0.25532803413482563),\n",
      " ('数据挖掘实操｜用文本挖掘剖析近5万首《全唐诗》', -0.929597257276769)]\n"
     ]
    }
   ],
   "source": [
    "result = [(docs[i[0]],i[1]) for i in vec_lsi]\n",
    "pprint(sorted(result,key=lambda x: x[1],reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25771837",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = similarities.MatrixSimilarity(lsi[corpus])  #将查询语料库转换到LSI向量空间并对其中的每个文档/语句建立索引\n",
    "#内存友好型接口\n",
    "#index = similarities.Similarity(output_prefix='Similarity',corpus=lsi[corpus],num_features=500)  #将查询语料库转换到LSI向量空间并对其中的每个文档/语句建立索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ad83459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('傅园慧和她的“洪荒之力”的大数据舆情分析', 0.87644345),\n",
      " ('以虎嗅网4W+文章的文本挖掘为例，展现数据分析的一整套流程', 0.82108116),\n",
      " ('Social Listening和传统市场调研的关系是怎样的？', 0.74482477),\n",
      " ('用大数据文本挖掘，来洞察“共享单车”的行业现状及走势', 0.6638191),\n",
      " ('以《大秦帝国之崛起》为例，来谈大数据舆情分析和文本挖掘', 0.63695246),\n",
      " ('揭开微博转发传播的规律：以“人民日报”发布的G20文艺晚会微博为例', 0.5492105),\n",
      " ('干货｜作为一个合格的“增长黑客”，你还得重视外部数据的分析！', 0.51892805),\n",
      " ('如何用数据分析，搞定新媒体运营的定位和内容初始化？', 0.5128285),\n",
      " ('文本挖掘从小白到精通（一）---语料、向量空间和模型的概念', 0.5031858),\n",
      " ('【新媒体运营实操】如何做出一个精美的个性化词云以哈尔滨冰雪大世界旅游的传播效应为例，谈数据新闻可视化的“魅惑”', 0.49039814),\n",
      " ('如何用聚类分析进行企业公众号的内容优化', 0.4471987),\n",
      " ('从社交媒体传播和文本挖掘角度解读《欢乐颂2》', 0.4446677),\n",
      " ('当数据分析遭遇心理动力学：用户深层次的情感需求浮出水面', 0.43081084),\n",
      " ('不懂数理和编程，如何运用免费的大数据工具获得行业洞察？', 0.41420436),\n",
      " ('如何利用Social Listening从社会化媒体中“提炼”有价值的信息？', 0.39105833),\n",
      " ('写给迷茫的你：如何运用运营思维规划自己的职业发展路径？', 0.3840393),\n",
      " ('数据挖掘实操｜用文本挖掘剖析近5万首《全唐诗》', 0.32529676),\n",
      " ('文本挖掘从小白到精通（三）---主题模型和文本数据转换', 0.31614575),\n",
      " ('文本挖掘从小白到精通（二）---语料库和词向量空间', 0.3131905),\n",
      " ('数据运营实操 | 如何运用数据分析对某个试运营项目进行“无死角”的复盘？', 0.26436985),\n",
      " ('数据运营|数据分析中，文本分析远比数值型分析重要！（上）', 0.25880426),\n",
      " ('万字干货｜10款数据分析“工具”，助你成为新媒体运营领域的“增长黑客”', 0.22302419),\n",
      " ('文本分类算法集锦，从小白到大牛，附代码注释和训练语料', 0.123448245),\n",
      " ('如何利用微信后台数据优化微信运营', 0.010427188)]\n"
     ]
    }
   ],
   "source": [
    "# 实施查询\n",
    "sims = index[vec_lsi]   \n",
    "result = [(docs[i[0]],i[1]) for i in enumerate(sims)]            # 对检索语料库进行相似度查询\n",
    "pprint(sorted(result ,key=lambda x: x[1],reverse=True))          # 每个查询结果的格式是 (语句， 与查询语句的相似度) ，是一个2元元组"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6d6972",
   "metadata": {},
   "source": [
    "#### 文本相似性度量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6f0e6a",
   "metadata": {},
   "source": [
    "衡量两个文本的相似性有很多种方法，如最直接的利用Hashcode，以及经典的欧氏距离、余弦距离等。  \n",
    "在比较两个文本集合（主要是基于主题模型的概率分布）的相似程度时，我们需要一些跟欧氏距离、余弦距离不同的相似度/距离度量方案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be09144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import ldamodel\n",
    "from gensim.matutils import kullback_leibler, jaccard, hellinger, sparse2full\n",
    "import numpy\n",
    "\n",
    "texts =  [\n",
    "  ['苹果','叶子','椭圆形','树上'],           \n",
    "  ['植物','叶子','绿色','落叶乔木'],           \n",
    "  ['水果','苹果','红彤彤','味道'],            \n",
    "  ['苹果','落叶乔木','树上','水果'],           \n",
    "  ['植物','营养','维生素'],           \n",
    "  ['营养','维生素','苹果','成分'],            \n",
    "  ['互联网','电脑','智能手机','高科技'],         \n",
    "  ['苹果','公司','互联网','品质'],          \n",
    "  ['乔布斯','苹果','硅谷'],          \n",
    "  ['电脑','智能手机','苹果','乔布斯'],         \n",
    "  ['苹果','电脑','品质','生意'],         \n",
    "  ['电脑','品质','乔布斯'],          \n",
    "  ['苹果','公司','生意','硅谷']]\n",
    "\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f41454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.170*\"苹果\" + 0.087*\"电脑\" + 0.064*\"品质\" + 0.063*\"乔布斯\" + 0.053*\"智能手机\" + 0.052*\"水果\" + 0.051*\"互联网\" + 0.049*\"树上\" + 0.049*\"公司\" + 0.042*\"生意\"'),\n",
       " (1,\n",
       "  '0.093*\"苹果\" + 0.082*\"植物\" + 0.075*\"维生素\" + 0.074*\"营养\" + 0.060*\"叶子\" + 0.058*\"落叶乔木\" + 0.051*\"成分\" + 0.049*\"绿色\" + 0.048*\"硅谷\" + 0.045*\"乔布斯\"')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.random.seed(2019) # 设置随机种子以获得每次相同的结果。\n",
    "model = ldamodel.LdaModel(corpus, id2word=dictionary, iterations=100, num_topics=2)\n",
    "model.show_topics(num_words=10) #展示主题模型，显示每个主题下的TOP10主题词"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bb1846",
   "metadata": {},
   "source": [
    "基于训练好的主题模型来比较文档之间的相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2d21bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = ['树上', '叶子', '植物']\n",
    "doc2 = ['乔布斯', '智能手机', '互联网']\n",
    "doc3 = [ '营养', '苹果','维生素']\n",
    "\n",
    "\n",
    "bow1 = model.id2word.doc2bow(doc1)  \n",
    "bow2 = model.id2word.doc2bow(doc2)   \n",
    "bow3 = model.id2word.doc2bow(doc3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bce07728",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_bow1 = model[bow1]\n",
    "lda_bow2 = model[bow2]\n",
    "lda_bow3 = model[bow3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f6e665",
   "metadata": {},
   "source": [
    "用Hellinger 和 Kullback–Leibler来度量上述语句之间的相似度/距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac13abe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.046444595428538994\n",
      "0.505161552997494\n",
      "0.4615085597971655\n"
     ]
    }
   ],
   "source": [
    "print(hellinger(lda_bow1, lda_bow3))\n",
    "print(hellinger(lda_bow2, lda_bow3))\n",
    "print(hellinger(lda_bow1, lda_bow2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fb442ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008893967\n",
      "1.0357668\n",
      "0.9507062\n"
     ]
    }
   ],
   "source": [
    "print(kullback_leibler(lda_bow1, lda_bow3))\n",
    "print(kullback_leibler(lda_bow2, lda_bow3))\n",
    "print(kullback_leibler(lda_bow1, lda_bow2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6b4ac5",
   "metadata": {},
   "source": [
    "利用Jaccard来度量文档之间的相似度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2177316",
   "metadata": {},
   "source": [
    "两个集合A和B的交集元素在A、B的并集中所占的比例，称为两个集合的杰卡德相似系数，用符号J(A,B)表示。  \n",
    "它用于比较有限样本集之间的相似性与差异性，Jaccard系数值越大，样本相似度越低"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a409e40",
   "metadata": {},
   "source": [
    "它的典型应用场景有：1 比较文本相似度，用于文本查重与去重 2 计算对象间距离，用于数据聚类等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34c7e84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard(bow1, bow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a9b2de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard(['苹果','大树','营养'], ['苹果','大树','营养'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7ec9de",
   "metadata": {},
   "source": [
    "#### 主题分布的距离度量（Distance Metrics for Topic Distributions）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d5bd92",
   "metadata": {},
   "source": [
    "假若，我们想知道这两个主题在语句距离上是多么的相近，该如何做"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3e227",
   "metadata": {},
   "source": [
    " 度量两个主题间的相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b038756",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_公司, topic_水果 = model.show_topics() \n",
    "\n",
    "#一些预处理，以使距离度量以可接受的数据形式来获得主题\n",
    "def make_topics_bow(topic):\n",
    "# 获取由model.show_topics（）返回的字符串，分割字符串以便分别获取主题和概率    \n",
    "    topic = topic.split('+')#用于存储主题bows的list    \n",
    "    topic_bow = []\n",
    "    for word in topic:#分隔概率和词汇       \n",
    "        prob, word = word.split('*')#去掉空格       \n",
    "        word = word.replace(\" \",\"\")       \n",
    "        word = word.replace('\"','')#词汇表示转换\n",
    "        #print(word)       \n",
    "        word = model.id2word.doc2bow([word])[0][0]       \n",
    "        topic_bow.append((word, float(prob)))\n",
    "    return topic_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4f772b",
   "metadata": {},
   "source": [
    "抽取“公司”、“水果”这两个主题的词汇分布，并展示“水果”这一主题的词汇分布情况："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "018f7fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "公司_distribution = make_topics_bow(topic_公司[1])\n",
    "水果_distribution = make_topics_bow(topic_水果[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa9675ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0.093),\n",
       " (4, 0.082),\n",
       " (10, 0.075),\n",
       " (11, 0.074),\n",
       " (0, 0.06),\n",
       " (6, 0.058),\n",
       " (12, 0.051),\n",
       " (5, 0.049),\n",
       " (20, 0.048),\n",
       " (19, 0.045)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以主题词汇加权表示的“水果”主题\n",
    "水果_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d5aaa62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6917495641343796"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hellinger(公司_distribution, 水果_distribution) # 返回值约为0.69，这意味着这2个主题在词汇分布方面存在一定差距\n",
    "                                               # 深层次的原因是 ---这两个主题所反映的语义存在差异。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
